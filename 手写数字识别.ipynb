{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手写数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-11T11:10:56.449910Z",
     "end_time": "2023-04-11T11:10:56.552880Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from data.mnist_dm import MNISTDataModule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-11T11:10:56.679880Z",
     "end_time": "2023-04-11T11:10:57.752943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.ops import Permute\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5),  # B * 1 * 28 * 28 -> B * 16 * 24 * 24\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # -> B * 16 * 12 * 12\n",
    "            nn.Conv2d(16, 24, 3),  # -> B * 24 * 10 * 10\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(24 * 10 * 10, 480),  # B * 2400 -> B * 480\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(480, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_size = x.size(0)\n",
    "        x = self.conv(x)\n",
    "        x = x.view(input_size, -1)\n",
    "\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "from torchvision.models.swin_transformer import SwinTransformerBlockV2, PatchMergingV2, swin_v2_t, Swin_V2_T_Weights\n",
    "\n",
    "\n",
    "class TransNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransNet, self).__init__()\n",
    "\n",
    "        self.embed_dim = 96\n",
    "\n",
    "        norm_layer = partial(nn.LayerNorm, eps=1e-5)\n",
    "\n",
    "        self.patch_embed = nn.Sequential(\n",
    "            nn.Conv2d(3, self.embed_dim, kernel_size=(4, 4), stride=(4, 4)),  # 3 * 28 * 28 -> 96 * 7 * 7\n",
    "            Permute([0, 2, 3, 1]),  # B C H W -> B H W C\n",
    "            norm_layer(self.embed_dim)  # 归一化\n",
    "        )\n",
    "\n",
    "        self.basic_block = nn.Sequential(  # 7 * 7 * 96 -> 7 * 7 * 96\n",
    "            SwinTransformerBlockV2(\n",
    "                dim=self.embed_dim,\n",
    "                num_heads=3,\n",
    "                shift_size=[0, 0],\n",
    "                window_size=[8, 8],\n",
    "            ),\n",
    "            SwinTransformerBlockV2(\n",
    "                dim=self.embed_dim,\n",
    "                num_heads=3,\n",
    "                shift_size=[4, 4],\n",
    "                window_size=[8, 8],\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.patch_merge = PatchMergingV2(  # 7 * 7 * 96 -> 4 * 4 * 192\n",
    "            dim=self.embed_dim,\n",
    "            norm_layer=norm_layer\n",
    "        )\n",
    "\n",
    "        self.permute = Permute([0, 3, 1, 2])  # B H W C -> B C H W\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flatten = nn.Flatten(1)\n",
    "\n",
    "        self.head = nn.Linear(192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)  # B * 7 * 7 * 96\n",
    "        x = self.basic_block(x)  # B * 7 * 7 * 96\n",
    "        x = self.patch_merge(x)  # B * 4 * 4 * 192\n",
    "\n",
    "        x = self.permute(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = TransNet()\n",
    "print('model loaded')\n",
    "\n",
    "output = model(imgs)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 系统"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module loaded\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "class TransLitModule(LightningModule):\n",
    "    def __init__(self, batch_size=32, lr=0.001):\n",
    "        super(TransLitModule, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = models.swin_v2_t()\n",
    "\n",
    "        self.loss_fn = CrossEntropyLoss()\n",
    "\n",
    "        self.acc = MulticlassAccuracy(num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "\n",
    "        preds = self(imgs)\n",
    "        loss = self.loss_fn(preds, labels)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "\n",
    "        pred = self(imgs)\n",
    "        loss = self.loss_fn(pred, labels)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "\n",
    "        pred = self(imgs)\n",
    "        loss = self.loss_fn(pred, labels)\n",
    "        self.acc(pred, labels)\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', self.acc, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "mnist_dm = MNISTDataModule('data')\n",
    "module = TransLitModule(256)\n",
    "print('module loaded')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T11:10:57.753944Z",
     "end_time": "2023-04-11T11:10:58.382703Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    save_top_k=3,\n",
    "    mode='min',\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger('logs', name='mnist')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T11:10:58.382703Z",
     "end_time": "2023-04-11T11:10:58.397706Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.tuner import Tuner\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=3,\n",
    "    precision='16-mixed',\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    num_sanity_val_steps=0,\n",
    "    # fast_dev_run=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T11:10:58.398706Z",
     "end_time": "2023-04-11T11:10:58.457702Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e838a1239b5446eb9900811988ed1500"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\miniconda3\\envs\\ML\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "LR finder stopped early after 83 steps due to diverging loss.\n",
      "Learning rate set to 4.786300923226383e-07\n",
      "Restoring states from the checkpoint path at D:\\OneDrive - stu.ahu.edu.cn\\code\\PYTHON\\LeML\\.lr_find_369d4961-7501-4954-86d0-759d1dcbde59.ckpt\n",
      "Restored all states from the checkpoint at D:\\OneDrive - stu.ahu.edu.cn\\code\\PYTHON\\LeML\\.lr_find_369d4961-7501-4954-86d0-759d1dcbde59.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 2 succeeded, trying batch size 4\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 4 succeeded, trying batch size 8\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 8 succeeded, trying batch size 16\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 16 succeeded, trying batch size 32\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 32 succeeded, trying batch size 64\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 64 succeeded, trying batch size 128\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 128 succeeded, trying batch size 256\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 256 succeeded, trying batch size 512\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 512 succeeded, trying batch size 1024\n",
      "Batch size 1024 failed, trying batch size 512\n",
      "Finished batch size finder, will continue with full run using batch size 512\n",
      "Restoring states from the checkpoint path at D:\\OneDrive - stu.ahu.edu.cn\\code\\PYTHON\\LeML\\.scale_batch_size_3a364554-983a-4a45-ad19-936886add4d3.ckpt\n",
      "Restored all states from the checkpoint at D:\\OneDrive - stu.ahu.edu.cn\\code\\PYTHON\\LeML\\.scale_batch_size_3a364554-983a-4a45-ad19-936886add4d3.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"batch_size\": 512\n",
      "\"lr\":         4.786300923226383e-07\n"
     ]
    }
   ],
   "source": [
    "tuner = Tuner(trainer)\n",
    "\n",
    "print(module.hparams)\n",
    "\n",
    "tuner.lr_find(module, datamodule=mnist_dm)\n",
    "tuner.scale_batch_size(module, datamodule=mnist_dm)\n",
    "\n",
    "print(module.hparams)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T11:10:58.458707Z",
     "end_time": "2023-04-11T11:22:44.401429Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-3285018fc40e57ef\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-3285018fc40e57ef\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T11:22:44.403429Z",
     "end_time": "2023-04-11T11:22:44.458426Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type               | Params\n",
      "-----------------------------------------------\n",
      "0 | model   | TransNet           | 28.4 M\n",
      "1 | loss_fn | CrossEntropyLoss   | 0     \n",
      "2 | acc     | MulticlassAccuracy | 0     \n",
      "-----------------------------------------------\n",
      "28.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.4 M    Total params\n",
      "113.446   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "daa08c4b4c8b421b87e29f664471ab88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d6c052eb60946509ebdc20c9c3a26a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9012f462686a49a284c6bcc3973c7b51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d049137eaa9345f3833e052c4e5242de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0337cd6ba7594b79965f62c2d30c6390"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.10579527169466019\r\n",
      "        test_loss            2.472641706466675\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'test_loss': 2.472641706466675, 'test_acc': 0.10579527169466019}]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.fit(module, datamodule=mnist_dm)\n",
    "\n",
    "trainer.test(module, datamodule=mnist_dm)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T11:22:44.417431Z",
     "end_time": "2023-04-11T11:27:50.316846Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
