{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600594483858",
   "display_name": "Python 3.8.5 64-bit ('l2t': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "# 单层神经网络\n",
    "全连接ReLU，1*隐藏层，无bias。x预测y，用L2 Loss\n",
    "- $H=W_1X$\n",
    "- $A=ReLU=max(0,H)$\n",
    "- $\\hat{y}=W_2A$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## numpy实现\n",
    "全程手动"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 30825387.714877978\n1 26424172.39503157\n2 25931791.17448231\n3 25141558.065359056\n4 21949806.089865733\n5 16451423.916932076\n6 10734886.314363547\n7 6379827.862905791\n8 3723791.8412019247\n9 2263690.501938464\n10 1489416.019937373\n11 1065569.8045618618\n12 817632.1548879102\n13 659182.732624602\n14 548804.064263481\n15 466435.7835879561\n16 401835.5505659876\n17 349380.1800640045\n18 305810.04649814736\n19 269088.3264597164\n20 237832.31781575707\n21 211033.65360617122\n22 187898.84717623558\n23 167811.55971874273\n24 150302.04319304804\n25 135017.24626753433\n26 121593.31139500231\n27 109752.55041803865\n28 99278.99515361668\n29 89993.59371460589\n30 81753.10248850787\n31 74402.36224686372\n32 67831.1194612197\n33 61944.71655773239\n34 56662.70320269985\n35 51912.86110214854\n36 47637.95946849718\n37 43774.624575904076\n38 40275.42877342538\n39 37101.12441426163\n40 34217.24621664119\n41 31592.58237826606\n42 29207.05152951455\n43 27026.65363741228\n44 25031.868900675265\n45 23203.572783756066\n46 21525.744924684495\n47 19984.80150562719\n48 18568.733148200816\n49 17264.21210687278\n50 16062.524677228937\n51 14954.27343840849\n52 13930.283213943743\n53 12983.748135849923\n54 12109.120433171429\n55 11300.521502443795\n56 10551.121101728937\n57 9856.674399930856\n58 9211.626676844702\n59 8612.681738246993\n60 8056.167800632877\n61 7538.451443187489\n62 7056.637376243068\n63 6608.522052086285\n64 6190.857834169898\n65 5801.756535883923\n66 5439.117930826264\n67 5100.680119835519\n68 4784.662251361286\n69 4489.618932223306\n70 4213.850166274943\n71 3956.224257310138\n72 3715.3576955638596\n73 3490.0812950837635\n74 3279.2132613136055\n75 3081.941438951107\n76 2897.0174211340495\n77 2723.8281651880507\n78 2561.5172541363295\n79 2409.4606471884626\n80 2266.7873669415503\n81 2133.0357337522955\n82 2007.481763636833\n83 1889.6717922909556\n84 1779.07381781115\n85 1675.2762823993335\n86 1577.7922368235186\n87 1486.2335547461444\n88 1400.160935902404\n89 1319.2725569950085\n90 1243.2313428815874\n91 1171.7594743095867\n92 1104.6152174773188\n93 1041.3957294626994\n94 981.9148086033014\n95 925.9667889698965\n96 873.313759781898\n97 823.7693354108741\n98 777.1777080888583\n99 733.3074271756881\n100 691.9959743152076\n101 653.0779424176778\n102 616.417735519297\n103 581.8873499389915\n104 549.3438451154951\n105 518.6742239401826\n106 489.7663079546329\n107 462.5178214895799\n108 436.83864965194164\n109 412.6256533032482\n110 389.778900614336\n111 368.22941373323215\n112 347.91450840754175\n113 328.7421841098088\n114 310.6589105799847\n115 293.5916526830481\n116 277.49166123787285\n117 262.28546579054523\n118 247.93148994845376\n119 234.39423935683237\n120 221.6065274656306\n121 209.52879638594038\n122 198.1250733176423\n123 187.3576234912001\n124 177.1953416366112\n125 167.59241132371403\n126 158.52284776752796\n127 149.9530290851267\n128 141.85935874325259\n129 134.21114020657222\n130 126.98320695736783\n131 120.15120468632679\n132 113.69685616550508\n133 107.59581028872859\n134 101.83016663518804\n135 96.37851350380062\n136 91.22546018280681\n137 86.35112117721687\n138 81.74203294318721\n139 77.38554938843373\n140 73.26708496062496\n141 69.3702207607194\n142 65.68403834678348\n143 62.19809658177724\n144 58.9025823889599\n145 55.78263501863688\n146 52.829828353444164\n147 50.036760853964196\n148 47.395593400897425\n149 44.895740831730606\n150 42.52925540132089\n151 40.28945029649981\n152 38.17023771190948\n153 36.16487167045051\n154 34.26667552090241\n155 32.46899757518398\n156 30.76756754033334\n157 29.156468538368152\n158 27.631048574753137\n159 26.186994027236324\n160 24.819469460238686\n161 23.52428564236135\n162 22.29772886369728\n163 21.137002581539782\n164 20.037408391187327\n165 18.99541007332646\n166 18.008048277839183\n167 17.073084290842917\n168 16.187721591256125\n169 15.348604733224265\n170 14.55364086049276\n171 13.800536242675834\n172 13.086987859019462\n173 12.41107278808349\n174 11.770315040045032\n175 11.163092789305477\n176 10.587691887353277\n177 10.042577028354254\n178 9.525743734248387\n179 9.035689963249318\n180 8.571288596742676\n181 8.13127873782017\n182 7.713920758945065\n183 7.318225596789715\n184 6.943057489214503\n185 6.587764854568178\n186 6.250869324960039\n187 5.931108946810878\n188 5.627891714176613\n189 5.3404897689180135\n190 5.06802183742\n191 4.809521110760812\n192 4.564382661147736\n193 4.331937176127804\n194 4.111516965339237\n195 3.9023861673686997\n196 3.7039552355159246\n197 3.5158092118755464\n198 3.3374149039182206\n199 3.1681081259954342\n200 3.0074579453887935\n201 2.8551048067109477\n202 2.7105434032776206\n203 2.573401971565991\n204 2.4432150665411045\n205 2.3196959825179992\n206 2.202535288522001\n207 2.0913665742349545\n208 1.9858176357471005\n209 1.8856824561125838\n210 1.7906903028292755\n211 1.7005170291829412\n212 1.6149253468599833\n213 1.5336986614764858\n214 1.4565892161646907\n215 1.3834035568365985\n216 1.313916791705486\n217 1.2479585892650393\n218 1.185380271815786\n219 1.1259478519449815\n220 1.0695311046562082\n221 1.015957000524049\n222 0.9651153678526176\n223 0.9168405271190929\n224 0.8709886341158097\n225 0.8274522914325877\n226 0.7861536912328784\n227 0.7469192394549455\n228 0.7096608634961602\n229 0.6742607851149689\n230 0.6406494505566932\n231 0.6087393431298153\n232 0.5784258783215215\n233 0.5496278927485718\n234 0.5222986838168258\n235 0.49634747018173847\n236 0.47168367125055727\n237 0.44824755323582444\n238 0.4259907781725148\n239 0.40486228149390063\n240 0.3847829164015616\n241 0.36571368051875874\n242 0.34758892223224547\n243 0.33039064314664424\n244 0.31403785711169346\n245 0.29849800684270017\n246 0.2837321579093021\n247 0.2697163635636376\n248 0.25639255536478717\n249 0.24372676357455508\n250 0.2316923651309687\n251 0.22027007462042722\n252 0.20940760346210124\n253 0.19908271179346843\n254 0.189272658868402\n255 0.1799571288353493\n256 0.17109790450399714\n257 0.1626795038294753\n258 0.15467766307332215\n259 0.14707563754836298\n260 0.13985104527093095\n261 0.13298025271554037\n262 0.12645103338649055\n263 0.12024697506353099\n264 0.11434927107359172\n265 0.10874066588383724\n266 0.10341116365311678\n267 0.09834484107117762\n268 0.09352943134602903\n269 0.08895294929489905\n270 0.0846007861177179\n271 0.08046271701203352\n272 0.07652885990671607\n273 0.0727882193882887\n274 0.06923298110670241\n275 0.06585211486870174\n276 0.0626389734199373\n277 0.05958311466337581\n278 0.05667804625931538\n279 0.05391383964915221\n280 0.051286253357466685\n281 0.0487886596855954\n282 0.04641344621785215\n283 0.04415375567195328\n284 0.04200456122331196\n285 0.039962380613235066\n286 0.03801951460397044\n287 0.03617213958928035\n288 0.03441412956732898\n289 0.03274337321953673\n290 0.031153994268894217\n291 0.029641903783394208\n292 0.028203553633168746\n293 0.026836618127223426\n294 0.025535880735231723\n295 0.02429808895528515\n296 0.02312114322863229\n297 0.022002261712712717\n298 0.020937524603041616\n299 0.01992410894791935\n300 0.018960373972449186\n301 0.018043644774823862\n302 0.017171551681593088\n303 0.01634165109609801\n304 0.01555279247044996\n305 0.014801710608577377\n306 0.014087389899498311\n307 0.013407622236081856\n308 0.012761045747353315\n309 0.012145590576369688\n310 0.011560130113938385\n311 0.011003377661311996\n312 0.01047334940367874\n313 0.00996886829265467\n314 0.009489022667279471\n315 0.009032906221381464\n316 0.00859833532376662\n317 0.008184716869316582\n318 0.007791229292332895\n319 0.007416985360405819\n320 0.007060655802720908\n321 0.006721512418217287\n322 0.006398884197096858\n323 0.006091814975432319\n324 0.005799679815008873\n325 0.005521517061055109\n326 0.005256786522209712\n327 0.005004779190763463\n328 0.004765023528423639\n329 0.0045367497131575405\n330 0.004319533537627526\n331 0.0041126934456687525\n332 0.003915896870618491\n333 0.0037286252871670603\n334 0.003550319965526625\n335 0.0033805536877569422\n336 0.0032189480332121163\n337 0.0030652067430643605\n338 0.0029187703884370982\n339 0.0027794027047381674\n340 0.002646692667896991\n341 0.0025204458585491446\n342 0.002400182643177283\n343 0.0022856912833013514\n344 0.0021767295121427398\n345 0.0020729914457222644\n346 0.001974207354448578\n347 0.0018801293516559313\n348 0.0017906028130625395\n349 0.00170534750002621\n350 0.0016241835697289996\n351 0.001546896543536244\n352 0.0014733090752693393\n353 0.0014032726017833052\n354 0.0013365637294063045\n355 0.0012730498945192463\n356 0.001212558760701864\n357 0.0011549404580061989\n358 0.0011000850247198971\n359 0.0010478814230594235\n360 0.0009981363429984414\n361 0.0009507692124113771\n362 0.0009056715465522434\n363 0.0008627564792974467\n364 0.0008218441998051151\n365 0.0007828769262659665\n366 0.0007457819878913804\n367 0.0007104561079411445\n368 0.0006768080308042709\n369 0.0006447568603638919\n370 0.0006142496216408094\n371 0.0005851746995566184\n372 0.000557497271642346\n373 0.0005311361521849982\n374 0.0005060217476532958\n375 0.0004820929889902858\n376 0.0004593078422014042\n377 0.0004376156257902763\n378 0.00041694237757510547\n379 0.00039724657888766\n380 0.0003784917835815529\n381 0.0003606387293577891\n382 0.0003436147859478591\n383 0.00032740085909476293\n384 0.00031196301601630423\n385 0.00029725518920037977\n386 0.00028324359452330653\n387 0.000269892825389148\n388 0.000257179800862544\n389 0.00024506232022688987\n390 0.00023352331725314012\n391 0.00022252761407634634\n392 0.00021205257221228882\n393 0.00020207001065013021\n394 0.00019256570590973568\n395 0.00018351209368087945\n396 0.00017488188538381585\n397 0.00016665838580898884\n398 0.0001588228727660941\n399 0.00015136364400071713\n400 0.00014424990397246442\n401 0.00013747307408569221\n402 0.00013101748755748086\n403 0.00012486737579589085\n404 0.00011900619054814247\n405 0.00011342082714552374\n406 0.00010809981573810246\n407 0.00010302847243716448\n408 9.819783830679962e-05\n409 9.359384996441742e-05\n410 8.920710835068665e-05\n411 8.502605950785917e-05\n412 8.104210356194242e-05\n413 7.724676977268712e-05\n414 7.362869082205079e-05\n415 7.018008960102176e-05\n416 6.689523339050067e-05\n417 6.376598955081535e-05\n418 6.0782082634419545e-05\n419 5.793769883463369e-05\n420 5.5227235902867585e-05\n421 5.264538305292776e-05\n422 5.0184074665025105e-05\n423 4.783836632096313e-05\n4244.5602671679577234e-05\n425 4.3471920820991916e-05\n426 4.1441352601733386e-05\n427 3.950574332234882e-05\n428 3.766132281659218e-05\n429 3.5902946146366694e-05\n430 3.422724783610179e-05\n431 3.263038285345737e-05\n432 3.110831779623013e-05\n433 2.9656766187304898e-05\n434 2.827327021025187e-05\n435 2.6955372234960922e-05\n436 2.5699129876113447e-05\n437 2.4501336204018125e-05\n438 2.3359309792705043e-05\n439 2.2271301569076342e-05\n440 2.1234208646027058e-05\n441 2.024504692645959e-05\n442 1.9302115632105764e-05\n443 1.8403774818312632e-05\n444 1.754731090772751e-05\n445 1.6730944920999133e-05\n446 1.595238525811637e-05\n447 1.5210350742620462e-05\n448 1.4502766990982076e-05\n449 1.3828390768552574e-05\n450 1.3185783454960686e-05\n451 1.2573010046270198e-05\n452 1.1988603526780599e-05\n453 1.1431412600449286e-05\n454 1.0900639356201742e-05\n455 1.0394273576110429e-05\n456 9.91151354607978e-06\n457 9.451259200297972e-06\n458 9.012720914340742e-06\n459 8.594559991672732e-06\n460 8.195641316538967e-06\n461 7.815366855379522e-06\n462 7.452854514999784e-06\n463 7.107290536694254e-06\n464 6.77775180649076e-06\n465 6.463561666812858e-06\n466 6.163940763050833e-06\n467 5.878206296936534e-06\n468 5.6058932441494145e-06\n469 5.346262967136871e-06\n470 5.098581831714077e-06\n471 4.86239513352384e-06\n472 4.637260476324329e-06\n473 4.422693748319644e-06\n474 4.217923542690834e-06\n475 4.0227145395784625e-06\n476 3.836592369127036e-06\n477 3.6591450352441795e-06\n478 3.4899023638683778e-06\n479 3.328472434742554e-06\n480 3.174554372084794e-06\n481 3.0278097717727177e-06\n482 2.8878885993021957e-06\n483 2.7544119362792756e-06\n484 2.627150587651383e-06\n485 2.5057608196052254e-06\n486 2.3899943599044406e-06\n487 2.279653081304814e-06\n488 2.1744016169078277e-06\n489 2.073991990899412e-06\n490 1.9782324852163377e-06\n491 1.886930771242787e-06\n492 1.799909263730924e-06\n493 1.7168521550711709e-06\n494 1.637629253847795e-06\n495 1.562080473322826e-06\n496 1.4900619151278668e-06\n497 1.4213591044635379e-06\n498 1.3558258128201098e-06\n499 1.2933300501605402e-06\n"
    }
   ],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 随机创建训练数据\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out) \n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "\n",
    "    # compute loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(it, loss)\n",
    "    \n",
    "    # Backward pass\n",
    "    # compute gradient\n",
    "\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h<0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "\n",
    "    # update weights of w1&w2\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练好的模型\n",
    "h = x.dot(w1)\n",
    "h_relu = np.maximum(h, 0)\n",
    "y_pred = h_relu.dot(w2)\n",
    "y_pred - y"
   ]
  },
  {
   "source": [
    "## pytorch实现\n",
    "### 1. tensor\n",
    "类似numpy， 可在GPU加速运算"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 38680648.0\n1 37410248.0\n2 38808292.0\n3 35763896.0\n4 26317700.0\n5 15317278.0\n6 7711322.5\n7 3907832.0\n8 2249604.25\n9 1509048.375\n10 1133082.25\n11 907271.0\n12 751118.75\n13 633096.6875\n14 539497.6875\n15 463305.0\n16 400235.40625\n17 347500.3125\n18 303122.1875\n19 265530.0\n20 233515.8125\n21 206085.8125\n22 182474.34375\n23 162033.8125\n24 144292.9375\n25 128812.6796875\n26 115281.7109375\n27 103404.4375\n28 92953.1875\n29 83724.640625\n30 75560.28125\n31 68315.5\n32 61873.3359375\n33 56134.7421875\n34 51015.83203125\n35 46432.828125\n36 42320.359375\n37 38622.43359375\n38 35293.7578125\n39 32291.03515625\n40 29579.720703125\n41 27126.14453125\n42 24901.77734375\n43 22882.10546875\n44 21047.58203125\n45 19377.57421875\n46 17854.66015625\n47 16466.177734375\n48 15197.48046875\n49 14037.7119140625\n50 12977.220703125\n51 12005.77734375\n52 11114.3681640625\n53 10296.0693359375\n54 9544.44140625\n55 8853.1484375\n56 8215.8896484375\n57 7629.33251953125\n58 7088.6865234375\n59 6590.0673828125\n60 6129.91796875\n61 5704.8115234375\n62 5312.2119140625\n63 4949.16455078125\n64 4613.05029296875\n65 4301.74365234375\n66 4013.41943359375\n67 3746.2392578125\n68 3498.5166015625\n69 3268.529296875\n70 3054.96484375\n71 2856.51220703125\n72 2672.061279296875\n73 2500.576416015625\n74 2340.876953125\n75 2192.21630859375\n76 2053.7578125\n77 1924.8006591796875\n78 1804.5731201171875\n79 1692.4530029296875\n80 1587.808837890625\n81 1490.1708984375\n82 1399.069091796875\n83 1313.99609375\n84 1234.4852294921875\n85 1160.1590576171875\n86 1090.6343994140625\n87 1025.61474609375\n88 964.7874145507812\n89 907.8231201171875\n90 854.4671020507812\n91 804.5155029296875\n92 757.68310546875\n93 713.7645874023438\n94 672.5809326171875\n95 633.8924560546875\n96 597.580078125\n97 563.5107421875\n98 531.52001953125\n99 501.47296142578125\n100 473.2433776855469\n101 446.73211669921875\n102 421.7976989746094\n103 398.35479736328125\n104 376.2983703613281\n105 355.55902099609375\n106 336.0350646972656\n107 317.6641845703125\n108 300.3622131347656\n109 284.0666809082031\n110 268.7138671875\n111 254.2495880126953\n112 240.61550903320312\n113 227.7609405517578\n114 215.63894653320312\n115 204.20809936523438\n116 193.42019653320312\n117 183.23739624023438\n118 173.6485595703125\n119 164.5974884033203\n120 156.04800415039062\n121 147.97459411621094\n122 140.3501434326172\n123 133.14645385742188\n124 126.33708190917969\n125 119.89942932128906\n126 113.81206512451172\n127 108.05146789550781\n128 102.60101318359375\n129 97.44184875488281\n130 92.55929565429688\n131 87.93746948242188\n132 83.55918884277344\n133 79.4106674194336\n134 75.48175811767578\n135 71.75938415527344\n136 68.22937774658203\n137 64.88922119140625\n138 61.7213249206543\n139 58.7173957824707\n140 55.869319915771484\n141 53.167930603027344\n142 50.60350799560547\n143 48.16987991333008\n144 45.860958099365234\n145 43.66734313964844\n146 41.586238861083984\n147 39.60780334472656\n148 37.729766845703125\n149 35.94513702392578\n150 34.249549865722656\n151 32.63752365112305\n152 31.105091094970703\n153 29.64963150024414\n154 28.26528549194336\n155 26.948129653930664\n156 25.695858001708984\n157 24.505016326904297\n158 23.37112808227539\n159 22.292491912841797\n160 21.266141891479492\n161 20.289451599121094\n162 19.360334396362305\n163 18.474613189697266\n164 17.631120681762695\n165 16.82917594909668\n166 16.064533233642578\n167 15.336271286010742\n168 14.642885208129883\n169 13.982017517089844\n170 13.352071762084961\n171 12.7513427734375\n172 12.179516792297363\n173 11.63368034362793\n174 11.113883018493652\n175 10.617935180664062\n176 10.145310401916504\n177 9.69437026977539\n178 9.264296531677246\n179 8.853924751281738\n180 8.462713241577148\n181 8.089459419250488\n182 7.73354959487915\n183 7.393503189086914\n184 7.069335460662842\n185 6.759414196014404\n186 6.463812828063965\n187 6.181650638580322\n188 5.912352085113525\n189 5.6548285484313965\n190 5.409215927124023\n191 5.174709320068359\n192 4.950353622436523\n193 4.736266613006592\n194 4.531859874725342\n195 4.336359024047852\n196 4.149666786193848\n197 3.970867156982422\n198 3.8004016876220703\n199 3.637712001800537\n200 3.481804847717285\n201 3.332965850830078\n202 3.1905088424682617\n203 3.0544724464416504\n204 2.9243574142456055\n205 2.799900770187378\n206 2.680877685546875\n207 2.566965103149414\n208 2.4583492279052734\n209 2.35418701171875\n210 2.25484037399292\n211 2.159552812576294\n212 2.0685291290283203\n213 1.9813703298568726\n214 1.89803147315979\n215 1.8181593418121338\n216 1.741807222366333\n217 1.6687464714050293\n218 1.5987789630889893\n219 1.531759262084961\n220 1.4677543640136719\n221 1.4063174724578857\n222 1.3476898670196533\n223 1.2914369106292725\n224 1.2377663850784302\n225 1.186286211013794\n226 1.1369192600250244\n227 1.0896703004837036\n228 1.0444074869155884\n229 1.001084566116333\n230 0.9597573280334473\n231 0.9200233221054077\n232 0.8819040656089783\n233 0.8456130027770996\n234 0.810675323009491\n235 0.7772022485733032\n236 0.745112419128418\n237 0.7144534587860107\n238 0.6851028203964233\n239 0.6569854021072388\n240 0.6299179792404175\n241 0.6040854454040527\n242 0.5793318748474121\n243 0.5556018352508545\n244 0.5328384041786194\n245 0.511093258857727\n246 0.49023595452308655\n247 0.47019872069358826\n248 0.45100831985473633\n249 0.4325549602508545\n250 0.41499102115631104\n251 0.3980955481529236\n252 0.38182419538497925\n253 0.3663056492805481\n254 0.35141825675964355\n255 0.3371392488479614\n256 0.32346585392951965\n257 0.31031644344329834\n258 0.297750860452652\n259 0.2857223451137543\n260 0.27410411834716797\n261 0.26305466890335083\n262 0.25235867500305176\n263 0.24221888184547424\n264 0.2324204444885254\n265 0.2230304777622223\n266 0.2140066921710968\n267 0.20540878176689148\n268 0.19714058935642242\n269 0.18924152851104736\n270 0.1815933883190155\n271 0.1742701381444931\n272 0.16725033521652222\n273 0.16053427755832672\n274 0.15411166846752167\n275 0.14792750775814056\n276 0.1420101523399353\n277 0.13633593916893005\n278 0.13086554408073425\n279 0.12563538551330566\n280 0.1205848678946495\n281 0.11575077474117279\n282 0.11115001887083054\n283 0.1067209243774414\n284 0.10244440287351608\n285 0.09835672378540039\n286 0.09443481266498566\n287 0.09065590798854828\n288 0.0870576947927475\n289 0.08358655124902725\n290 0.080240398645401\n291 0.07705320417881012\n292 0.07401251047849655\n293 0.07107170671224594\n294 0.0682511106133461\n295 0.06554435193538666\n296 0.06293576955795288\n297 0.060437433421611786\n298 0.05804602429270744\n299 0.055734194815158844\n300 0.05353508144617081\n301 0.051411475986242294\n302 0.04937542602419853\n303 0.04741988331079483\n304 0.045561499893665314\n305 0.04377066344022751\n306 0.042049042880535126\n307 0.04038296639919281\n308 0.038805268704891205\n309 0.037276167422533035\n310 0.035804763436317444\n311 0.034397970885038376\n312 0.03305382654070854\n313 0.031758058816194534\n314 0.030514486134052277\n315 0.02931145392358303\n316 0.02817135490477085\n317 0.027073334902524948\n318 0.02601432055234909\n319 0.024998171254992485\n320 0.024031605571508408\n321 0.02307698503136635\n322 0.022191159427165985\n323 0.021335411816835403\n324 0.020495500415563583\n325 0.01970214769244194\n326 0.018938766792416573\n327 0.018192995339632034\n328 0.017490526661276817\n329 0.016817042604088783\n330 0.016171667724847794\n331 0.015553884208202362\n332 0.014952048659324646\n333 0.014375193044543266\n334 0.01382341980934143\n335 0.01329362764954567\n336 0.012792610563337803\n337 0.01230149157345295\n338 0.011822800152003765\n339 0.011379427276551723\n340 0.010946142487227917\n341 0.010534712113440037\n342 0.010132419876754284\n343 0.009744829498231411\n344 0.00937724020332098\n345 0.009022805839776993\n346 0.008685360662639141\n347 0.008352784439921379\n348 0.008045719005167484\n349 0.007743878290057182\n350 0.007449271623045206\n351 0.007171856705099344\n352 0.0069092558696866035\n353 0.006653539836406708\n354 0.006400476675480604\n355 0.006165863946080208\n356 0.005936452653259039\n357 0.005717334803193808\n358 0.005506980232894421\n359 0.005310508888214827\n360 0.005114380270242691\n361 0.004922837018966675\n362 0.004748671315610409\n363 0.00457423273473978\n364 0.004413040354847908\n365 0.004252118058502674\n366 0.00410359725356102\n367 0.003953487146645784\n368 0.0038139531388878822\n369 0.0036808066070079803\n370 0.0035487054847180843\n371 0.0034276614896953106\n372 0.003306942991912365\n373 0.0031913979910314083\n374 0.0030823457054793835\n375 0.002975237788632512\n376 0.002871693577617407\n377 0.0027768011204898357\n378 0.0026834188029170036\n379 0.002591824159026146\n380 0.002502154093235731\n381 0.0024195071309804916\n382 0.002340987790375948\n383 0.0022641392424702644\n384 0.0021912476513534784\n385 0.0021141478791832924\n386 0.0020438693463802338\n387 0.001977634383365512\n388 0.0019124310929328203\n389 0.0018508338835090399\n390 0.0017925110878422856\n391 0.0017341823549941182\n392 0.001677894964814186\n393 0.0016243550926446915\n394 0.001572227105498314\n395 0.0015246113762259483\n396 0.0014766380190849304\n397 0.0014308332465589046\n398 0.0013878030003979802\n399 0.001345879165455699\n400 0.0013036057353019714\n401 0.001265619765035808\n402 0.0012263463577255607\n403 0.0011895340867340565\n404 0.0011554223019629717\n405 0.0011211922392249107\n406 0.0010883433278650045\n407 0.0010563632240518928\n408 0.001026609563268721\n409 0.0009974970016628504\n410 0.000967077212408185\n411 0.0009414652013219893\n412 0.0009136728476732969\n413 0.0008867022697813809\n414 0.0008620321750640869\n415 0.0008387521374970675\n416 0.000815844745375216\n417 0.0007928904378786683\n418 0.0007711932994425297\n419 0.0007521018269471824\n420 0.0007313552778214216\n421 0.0007115674088709056\n422 0.0006938878213986754\n423 0.0006755476351827383\n424 0.0006575151928700507\n425 0.0006412499351426959\n426 0.0006243808893486857\n427 0.0006093551055528224\n428 0.0005940997507423162\n429 0.0005783695378340781\n430 0.0005645019700750709\n431 0.0005507314344868064\n432 0.0005382378003560007\n433 0.0005237657460384071\n434 0.0005115063395351171\n435 0.0004989370936527848\n436 0.00048774710739962757\n437 0.00047610350884497166\n438 0.00046461186138913035\n439 0.00045378057984635234\n440 0.0004428778192959726\n441 0.00043245850247330964\n442 0.0004216879606246948\n443 0.00041212403448298573\n444 0.0004030836862511933\n445 0.0003936496505048126\n446 0.0003852553782053292\n447 0.0003766521404031664\n448 0.0003678054199554026\n449 0.00035967491567134857\n450 0.0003516486322041601\n451 0.0003443341120146215\n452 0.0003360434784553945\n453 0.000328904134221375\n454 0.0003213685704395175\n455 0.00031472890987060964\n456 0.00030805543065071106\n457 0.00030079681891947985\n458 0.00029512064065784216\n459 0.0002894432400353253\n460 0.00028356589609757066\n461 0.00027753657195717096\n462 0.00027193789719603956\n463 0.0002663847408257425\n464 0.0002611570816952735\n465 0.00025617447681725025\n466 0.000251367746386677\n467 0.0002453313209116459\n468 0.00024038853007368743\n469 0.0002361268416279927\n470 0.00023185310419648886\n471 0.00022698227257933468\n472 0.00022303858713712543\n473 0.00021838422981090844\n474 0.00021443919104058295\n475 0.00021007165196351707\n476 0.00020584577578119934\n477 0.0002016788930632174\n478 0.00019749173952732235\n479 0.00019407979561947286\n480 0.00019069270638283342\n481 0.00018707316485233605\n482 0.00018353431369177997\n483 0.0001801408943720162\n484 0.00017678023141343147\n485 0.00017377265612594783\n486 0.00017083405691664666\n487 0.00016789270739536732\n488 0.00016504045925103128\n489 0.00016240219702012837\n490 0.00015939907461870462\n491 0.00015664326201658696\n492 0.00015427556354552507\n493 0.00015137146692723036\n494 0.00014871884195599705\n495 0.0001464411470806226\n496 0.00014395240577869117\n497 0.0001414846337866038\n498 0.0001394899154547602\n499 0.00013704532466363162\n"
    }
   ],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 随机创建训练数据\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "w1 = torch.randn(D_in, H)\n",
    "w2 = torch.randn(H, D_out) \n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.m(w2)\n",
    "\n",
    "    # compute loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    print(it, loss)\n",
    "    \n",
    "    # Backward pass\n",
    "    # compute gradient\n",
    "\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h<0] = 0\n",
    "    grad_w1 = x.T.mm(grad_h)\n",
    "\n",
    "    # update weights of w1&w2\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "source": [
    "autograd"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(1.) tensor(2.) tensor(1.)\n"
    }
   ],
   "source": [
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "y = w*x + b # y = 2*1 + 3\n",
    "\n",
    "y.backward()\n",
    "\n",
    "# dy / dw = x\n",
    "print(w.grad, x.grad, b.grad)\n"
   ]
  },
  {
   "source": [
    "### 2. torch + autograd\n",
    "自动求导所有参数梯度"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 32329088.0\n1 28430886.0\n2 25814546.0\n3 21692844.0\n4 16014325.0\n5 10525513.0\n6 6430998.5\n7 3913725.25\n8 2488612.25\n9 1702237.0\n10 1251896.875\n11 976648.5\n12 794140.125\n13 663772.8125\n14 564831.0\n15 486478.65625\n16 422603.625\n17 369450.1875\n18 324602.0625\n19 286418.90625\n20 253704.03125\n21 225448.28125\n22 200947.546875\n23 179607.53125\n24 160919.28125\n25 144592.1875\n26 130190.046875\n27 117451.4453125\n28 106149.296875\n29 96131.6171875\n30 87208.25\n31 79230.734375\n32 72091.84375\n33 65684.6171875\n34 59922.2265625\n35 54727.90625\n36 50039.3515625\n37 45798.5390625\n38 41959.93359375\n39 38480.50390625\n40 35322.41796875\n41 32453.037109375\n42 29846.5546875\n43 27472.35546875\n44 25306.689453125\n45 23327.138671875\n46 21517.76953125\n47 19861.38671875\n48 18344.009765625\n49 16953.4921875\n50 15677.9326171875\n51 14506.2646484375\n52 13429.140625\n53 12438.294921875\n54 11526.7919921875\n55 10686.517578125\n56 9912.150390625\n57 9197.7373046875\n58 8538.646484375\n59 7930.1162109375\n60 7367.61962890625\n61 6847.58056640625\n62 6366.4443359375\n63 5921.26171875\n64 5509.10986328125\n65 5127.185546875\n66 4773.111328125\n67 4445.05078125\n68 4140.54736328125\n69 3857.893310546875\n70 3595.40869140625\n71 3351.669921875\n72 3125.29833984375\n73 2914.896728515625\n74 2719.2626953125\n75 2537.38427734375\n76 2368.127197265625\n77 2210.662841796875\n78 2064.103759765625\n79 1927.6439208984375\n80 1800.726318359375\n81 1682.48193359375\n82 1572.291259765625\n83 1469.641845703125\n84 1373.862548828125\n85 1284.544921875\n86 1201.2354736328125\n87 1123.5472412109375\n88 1051.048583984375\n89 983.3870849609375\n90 920.2109375\n91 861.2169799804688\n92 806.130126953125\n93 754.6767578125\n94 706.5859375\n95 661.6375122070312\n96 619.6467895507812\n97 580.3970947265625\n98 543.69140625\n99 509.3695983886719\n100 477.26019287109375\n101 447.23565673828125\n102 419.13922119140625\n103 392.847900390625\n104 368.2412109375\n105 345.22955322265625\n106 323.676025390625\n107 303.505859375\n108 284.6148681640625\n109 266.9227600097656\n110 250.35545349121094\n111 234.84510803222656\n112 220.31076049804688\n113 206.6944122314453\n114 193.93328857421875\n115 181.98348999023438\n116 170.78558349609375\n117 160.28477478027344\n118 150.4420928955078\n119 141.21502685546875\n120 132.5657501220703\n121 124.4566421508789\n122 116.85029602050781\n123 109.71788024902344\n124 103.03041076660156\n125 96.75901794433594\n126 90.87488555908203\n127 85.35499572753906\n128 80.17234802246094\n129 75.31108093261719\n130 70.75080108642578\n131 66.46971130371094\n132 62.45308303833008\n133 58.682735443115234\n134 55.142982482910156\n135 51.82029724121094\n136 48.70023727416992\n137 45.77289581298828\n138 43.022708892822266\n139 40.44055938720703\n140 38.015079498291016\n141 35.73770523071289\n142 33.59918975830078\n143 31.590946197509766\n144 29.70301628112793\n145 27.92905044555664\n146 26.264528274536133\n147 24.699390411376953\n148 23.22945785522461\n149 21.847679138183594\n150 20.549625396728516\n151 19.32868194580078\n152 18.182226181030273\n153 17.104679107666016\n154 16.09183120727539\n155 15.139711380004883\n156 14.24545955657959\n157 13.403837203979492\n158 12.612709045410156\n159 11.86883544921875\n160 11.16909122467041\n161 10.511734008789062\n162 9.892861366271973\n163 9.311561584472656\n164 8.76457405090332\n165 8.24958324432373\n166 7.766141414642334\n167 7.310882568359375\n168 6.882537364959717\n169 6.4799485206604\n170 6.101225852966309\n171 5.744640827178955\n172 5.409321308135986\n173 5.093603134155273\n174 4.796780109405518\n175 4.517115592956543\n176 4.254271030426025\n177 4.006646633148193\n178 3.773905038833618\n179 3.554431676864624\n180 3.348273515701294\n181 3.1542253494262695\n182 2.9714651107788086\n183 2.7993175983428955\n184 2.637227773666382\n185 2.484797239303589\n186 2.3411712646484375\n187 2.205848217010498\n188 2.0786571502685547\n189 1.958691120147705\n190 1.8457679748535156\n191 1.7396469116210938\n192 1.639448881149292\n193 1.5452016592025757\n194 1.4564104080200195\n195 1.3727364540100098\n196 1.2940258979797363\n197 1.2197741270065308\n198 1.1498382091522217\n199 1.083870530128479\n200 1.0218214988708496\n201 0.9633245468139648\n202 0.908305287361145\n203 0.8564289808273315\n204 0.8075722455978394\n205 0.7615349292755127\n206 0.7180485725402832\n207 0.6772096157073975\n208 0.6385958790779114\n209 0.6022768020629883\n210 0.5680347681045532\n211 0.5357296466827393\n212 0.5053385496139526\n213 0.47667694091796875\n214 0.44954752922058105\n215 0.4240688979625702\n216 0.40011894702911377\n217 0.3774681091308594\n218 0.35606956481933594\n219 0.3359987735748291\n220 0.3169954717159271\n221 0.29916074872016907\n222 0.28228724002838135\n223 0.26639318466186523\n224 0.25133487582206726\n225 0.23724202811717987\n226 0.22386448085308075\n227 0.2112908959388733\n228 0.19935108721256256\n229 0.18821102380752563\n230 0.1776503175497055\n231 0.1676584631204605\n232 0.15827113389968872\n233 0.14939269423484802\n234 0.14103229343891144\n235 0.13313770294189453\n236 0.12568795680999756\n237 0.11868231743574142\n238 0.11206859350204468\n239 0.10578823834657669\n240 0.09990708529949188\n241 0.09433554112911224\n242 0.08910252153873444\n243 0.08413773030042648\n244 0.07942229509353638\n245 0.07501243054866791\n246 0.07080492377281189\n247 0.06689409911632538\n248 0.0631791427731514\n249 0.0596981942653656\n250 0.05639518052339554\n251 0.05328405275940895\n252 0.05035163834691048\n253 0.047572020441293716\n254 0.044952839612960815\n255 0.042459242045879364\n256 0.04010511189699173\n257 0.03789956867694855\n258 0.035824086517095566\n259 0.033824943006038666\n260 0.03196755796670914\n261 0.03021460957825184\n262 0.028569567948579788\n263 0.027006572112441063\n264 0.025522656738758087\n265 0.024135708808898926\n266 0.022813599556684494\n267 0.02156876027584076\n268 0.0203868355602026\n269 0.019289815798401833\n270 0.018242407590150833\n271 0.01725158840417862\n272 0.016312535852193832\n273 0.015434086322784424\n274 0.014599611051380634\n275 0.013815599493682384\n276 0.013062807731330395\n277 0.012368209660053253\n278 0.01170285977423191\n279 0.011077642440795898\n280 0.010484605096280575\n281 0.009929352439939976\n282 0.009402218274772167\n283 0.008909346535801888\n284 0.008441495709121227\n285 0.00798867829144001\n286 0.007573702838271856\n287 0.007175168488174677\n288 0.006796716246753931\n289 0.006440703757107258\n290 0.006107066757977009\n291 0.005793075077235699\n292 0.005490050185471773\n293 0.005213162396103144\n294 0.004947064444422722\n295 0.004688214045017958\n296 0.004450680688023567\n297 0.004226477816700935\n298 0.004018623381853104\n299 0.0038158083334565163\n300 0.0036248459946364164\n301 0.0034457945730537176\n302 0.0032756896689534187\n303 0.0031152202282100916\n304 0.0029636791441589594\n305 0.0028192009776830673\n306 0.0026831685099750757\n307 0.0025581205263733864\n308 0.0024355784989893436\n309 0.002323059132322669\n310 0.0022119127679616213\n311 0.0021077634301036596\n312 0.002011730335652828\n313 0.0019188025034964085\n314 0.0018316328059881926\n315 0.001749419723637402\n316 0.0016682383138686419\n317 0.00159626011736691\n318 0.0015257908962666988\n319 0.001459380378946662\n320 0.0013949896674603224\n321 0.0013367518549785018\n322 0.0012784780701622367\n323 0.0012241678778082132\n324 0.0011725409422069788\n325 0.001123163034208119\n326 0.001078623696230352\n327 0.0010326391784474254\n328 0.0009895144030451775\n329 0.000953001668676734\n330 0.000914908479899168\n331 0.0008774759480729699\n332 0.0008423127001151443\n333 0.0008111835340969265\n334 0.0007785605266690254\n335 0.0007487968541681767\n336 0.0007214691140688956\n337 0.0006937985890544951\n338 0.0006673928000964224\n339 0.0006418566918000579\n340 0.0006179829360917211\n341 0.0005960597773082554\n342 0.0005759340128861368\n343 0.0005556624382734299\n344 0.0005358455237001181\n345 0.0005163399036973715\n346 0.0005007577128708363\n347 0.00048338546184822917\n348 0.0004666492168325931\n349 0.00045066169695928693\n350 0.00043582345824688673\n351 0.0004212507337797433\n352 0.0004072481533512473\n353 0.0003946249489672482\n354 0.0003821392892859876\n355 0.0003700551751535386\n356 0.0003574203874450177\n357 0.0003465107292868197\n358 0.0003364872245583683\n359 0.00032570515759289265\n360 0.0003156217862851918\n361 0.0003062926116399467\n362 0.0002973038936033845\n363 0.0002884051064029336\n364 0.00027988204965367913\n365 0.000271322118351236\n366 0.00026339778560213745\n367 0.00025638818624429405\n368 0.0002491050399839878\n369 0.00024136602587532252\n370 0.00023452553432434797\n371 0.00022848912340123206\n372 0.00022147447452880442\n373 0.00021546454809140414\n374 0.0002099907142110169\n375 0.00020372297149151564\n376 0.00019899269682355225\n377 0.00019350691582076252\n378 0.00018835259834304452\n379 0.00018360718968324363\n380 0.00017898203805088997\n381 0.0001739158615237102\n382 0.0001695537066552788\n383 0.00016570580191910267\n384 0.00016124401008710265\n385 0.0001573033950990066\n386 0.00015315051132347435\n387 0.00014916161308065057\n388 0.0001455746969440952\n389 0.0001425100927008316\n390 0.00013843881606590003\n391 0.00013535308244172484\n392 0.0001317478745477274\n393 0.00012847862672060728\n394 0.00012576105655170977\n395 0.00012286758283153176\n396 0.00012044407776556909\n397 0.00011779906344600022\n398 0.00011477443331386894\n399 0.0001122260800912045\n400 0.00010944050882244483\n401 0.00010708467016229406\n402 0.0001051225553965196\n403 0.00010270622442476451\n404 0.00010078931518364698\n405 9.81774355750531e-05\n406 9.603190119378269e-05\n407 9.428246266907081e-05\n408 9.19415833777748e-05\n409 8.961280400399119e-05\n410 8.81179585121572e-05\n411 8.672942931298167e-05\n412 8.5034582298249e-05\n413 8.310415432788432e-05\n414 8.163915481418371e-05\n415 8.014125342015177e-05\n416 7.834429561626166e-05\n417 7.699287380091846e-05\n418 7.541245577158406e-05\n419 7.403980998788029e-05\n420 7.295641262317076e-05\n421 7.14622947270982e-05\n422 7.034957525320351e-05\n423 6.904889596626163e-05\n424 6.733092595823109e-05\n425 6.616916653001681e-05\n426 6.512923573609442e-05\n427 6.416762334993109e-05\n428 6.281193782342598e-05\n429 6.173592555569485e-05\n430 6.0652211686829105e-05\n431 5.978285844321363e-05\n432 5.875273927813396e-05\n433 5.74055957258679e-05\n434 5.6676835811231285e-05\n435 5.5761604016879573e-05\n436 5.503483771462925e-05\n437 5.396751294028945e-05\n438 5.34351565875113e-05\n439 5.260442412691191e-05\n440 5.167169729247689e-05\n441 5.1049184548901394e-05\n442 5.014333873987198e-05\n443 4.9288300942862406e-05\n444 4.8285441152984276e-05\n445 4.7625781007809564e-05\n446 4.6751476475037634e-05\n447 4.6290817408589646e-05\n448 4.557841020869091e-05\n449 4.489548518904485e-05\n450 4.436552262632176e-05\n451 4.347240610513836e-05\n452 4.2862913687713444e-05\n453 4.2393585317768157e-05\n454 4.1816732846200466e-05\n455 4.1185492591466755e-05\n456 4.0553361031925306e-05\n457 4.0120386984199286e-05\n458 3.946160359191708e-05\n459 3.905934136128053e-05\n460 3.8381771446438506e-05\n461 3.7881898606428877e-05\n462 3.746522997971624e-05\n463 3.6940986319677904e-05\n464 3.640673094196245e-05\n465 3.582832869142294e-05\n466 3.542962440405972e-05\n467 3.4988217521458864e-05\n468 3.455950354691595e-05\n469 3.413703598198481e-05\n470 3.3845244615804404e-05\n471 3.347217716509476e-05\n472 3.305361315142363e-05\n473 3.250669396948069e-05\n474 3.214831303921528e-05\n475 3.1656443752581254e-05\n476 3.136575105600059e-05\n477 3.10861250909511e-05\n478 3.072552863159217e-05\n479 3.0271159630501643e-05\n480 2.998738818860147e-05\n481 2.973801747430116e-05\n482 2.927829154941719e-05\n483 2.9065142371109687e-05\n484 2.8577871489687823e-05\n485 2.8350033971946687e-05\n486 2.7961499654338695e-05\n487 2.758971277216915e-05\n488 2.7312729798723012e-05\n489 2.6978948881151155e-05\n490 2.6820203856914304e-05\n491 2.6553454517852515e-05\n492 2.6238874852424487e-05\n493 2.594106445030775e-05\n494 2.578023304522503e-05\n495 2.553630474722013e-05\n496 2.51154324359959e-05\n497 2.4985172785818577e-05\n498 2.4792481781332754e-05\n499 2.445407517370768e-05\n"
    }
   ],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 随机创建训练数据\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "w1 = torch.randn(D_in, H, requires_grad=True)# 需要计算梯度\n",
    "w2 = torch.randn(H, D_out, requires_grad=True) \n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    # compute loss\n",
    "    loss = (y_pred - y).pow(2).sum() # computation graph\n",
    "    print(it, loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # update weights of w1&w2\n",
    "    with torch.no_grad():# 不让计算图占内存\n",
    "        w1 -= learning_rate * w1.grad # 所有tensor运算属于计算图\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        w1.grad.zero_() # 清0，否则不断叠加\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "source": [
    "### 3. nn | nural net"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 27049660.0\n1 20304284.0\n2 15793264.0\n3 12005248.0\n4 8828522.0\n5 6306160.0\n6 4467661.0\n7 3185989.5\n8 2320843.0\n9 1737293.25\n10 1339322.125\n11 1060529.75\n12 859409.5\n13 710004.3125\n14 595719.125\n15 505926.5625\n16 433675.09375\n17 374515.65625\n18 325361.75\n19 284114.34375\n20 249176.4375\n21 219354.90625\n22 193736.1875\n23 171668.9375\n24 152538.65625\n25 135883.46875\n26 121323.4375\n27 108564.859375\n28 97346.703125\n29 87455.7421875\n30 78698.65625\n31 70940.140625\n32 64061.578125\n33 57936.796875\n34 52478.8359375\n35 47600.7109375\n36 43231.421875\n37 39313.0703125\n38 35787.07421875\n39 32615.515625\n40 29759.14453125\n41 27180.224609375\n42 24850.9140625\n43 22744.19140625\n44 20836.673828125\n45 19107.009765625\n46 17537.1015625\n47 16109.0546875\n48 14809.3154296875\n49 13625.1982421875\n50 12545.26953125\n51 11559.7607421875\n52 10660.068359375\n53 9837.37109375\n54 9083.7509765625\n55 8393.39453125\n56 7760.5859375\n57 7179.54638671875\n58 6646.306640625\n59 6156.02978515625\n60 5705.11083984375\n61 5289.908203125\n62 4907.52880859375\n63 4555.19287109375\n64 4230.146484375\n65 3930.35986328125\n66 3653.358642578125\n67 3397.395751953125\n68 3160.783935546875\n69 2941.90478515625\n70 2739.30078125\n71 2551.76708984375\n72 2378.005615234375\n73 2216.869140625\n74 2067.4306640625\n75 1928.7425537109375\n76 1799.9835205078125\n77 1680.4146728515625\n78 1569.38330078125\n79 1466.1009521484375\n80 1370.0211181640625\n81 1280.664306640625\n82 1197.5162353515625\n83 1120.087890625\n84 1047.97314453125\n85 980.8422241210938\n86 918.190673828125\n87 859.7647705078125\n88 805.2703857421875\n89 754.4246215820312\n90 706.9691772460938\n91 662.663818359375\n92 621.31298828125\n93 582.748779296875\n94 546.6978149414062\n95 512.9998168945312\n96 481.487548828125\n97 451.9983215332031\n98 424.40106201171875\n99 398.5964050292969\n100 374.4149475097656\n101 351.77301025390625\n102 330.5621032714844\n103 310.69146728515625\n104 292.075927734375\n105 274.61871337890625\n106 258.2569580078125\n107 242.91004943847656\n108 228.50881958007812\n109 214.99440002441406\n110 202.3159637451172\n111 190.41336059570312\n112 179.24072265625\n113 168.74468994140625\n114 158.85287475585938\n115 149.5590362548828\n116 140.8278350830078\n117 132.62867736816406\n118 124.92326354980469\n119 117.68272399902344\n120 110.87837219238281\n121 104.4778823852539\n122 98.46556091308594\n123 92.80696868896484\n124 87.48435974121094\n125 82.47722625732422\n126 77.7653579711914\n127 73.33281707763672\n128 69.15866088867188\n129 65.23052978515625\n130 61.537147521972656\n131 58.05459976196289\n132 54.777042388916016\n133 51.6883430480957\n134 48.77897262573242\n135 46.037776947021484\n136 43.45585632324219\n137 41.02329635620117\n138 38.730743408203125\n13936.56947326660156\n140 34.53153991699219\n141 32.61053466796875\n142 30.798221588134766\n143 29.089982986450195\n144 27.47907066345215\n145 25.95929527282715\n146 24.526371002197266\n147 23.174943923950195\n148 21.89895248413086\n149 20.69525146484375\n150 19.55890655517578\n151 18.486066818237305\n152 17.474544525146484\n153 16.51955795288086\n154 15.617216110229492\n155 14.765686988830566\n156 13.962257385253906\n157 13.202576637268066\n158 12.48551082611084\n159 11.808294296264648\n160 11.168264389038086\n161 10.563545227050781\n162 9.992574691772461\n163 9.453688621520996\n164 8.94398021697998\n165 8.462656021118164\n166 8.006888389587402\n167 7.576669692993164\n168 7.169996738433838\n169 6.7856926918029785\n170 6.422128677368164\n171 6.078680038452148\n172 5.753979682922363\n173 5.446807861328125\n174 5.156276226043701\n175 4.881831169128418\n176 4.6218647956848145\n177 4.376123905181885\n178 4.144068717956543\n179 3.924272060394287\n180 3.7162113189697266\n181 3.5193467140197754\n182 3.3331103324890137\n183 3.157172203063965\n184 2.9903955459594727\n185 2.8327274322509766\n186 2.683506965637207\n187 2.5422163009643555\n188 2.4085733890533447\n189 2.28200101852417\n190 2.1622180938720703\n191 2.0488061904907227\n192 1.9414364099502563\n193 1.8397514820098877\n194 1.7435449361801147\n195 1.6524546146392822\n196 1.5661306381225586\n197 1.4845547676086426\n198 1.4070998430252075\n199 1.3337076902389526\n200 1.2644150257110596\n201 1.1985763311386108\n202 1.136342167854309\n203 1.0774427652359009\n204 1.0214444398880005\n205 0.9685183167457581\n206 0.9182876348495483\n207 0.8708822727203369\n208 0.8256968855857849\n209 0.7831751108169556\n210 0.742730438709259\n211 0.7044225931167603\n212 0.6680743098258972\n213 0.6337467432022095\n214 0.6011210083961487\n215 0.570172905921936\n216 0.5408502221107483\n217 0.5130964517593384\n218 0.4868258237838745\n219 0.4618525505065918\n220 0.43815988302230835\n221 0.4157427251338959\n222 0.39449769258499146\n223 0.3742767572402954\n224 0.3552192449569702\n225 0.33708444237709045\n226 0.31988778710365295\n227 0.3035459816455841\n228 0.2880899906158447\n229 0.27338704466819763\n230 0.25945788621902466\n231 0.2463092803955078\n232 0.23380059003829956\n233 0.2219025045633316\n234 0.21066471934318542\n235 0.19998103380203247\n236 0.1898227334022522\n237 0.18018750846385956\n238 0.1710721254348755\n239 0.1624504178762436\n240 0.15425553917884827\n241 0.14639636874198914\n242 0.1390451192855835\n243 0.13199032843112946\n244 0.12536576390266418\n245 0.11905251443386078\n246 0.11302636563777924\n247 0.10736261308193207\n248 0.10196390748023987\n249 0.0968383401632309\n250 0.09195404499769211\n251 0.08735406398773193\n252 0.08299075067043304\n253 0.07881899923086166\n254 0.07483994960784912\n255 0.07108455896377563\n256 0.06753911077976227\n257 0.06416290998458862\n258 0.06093220412731171\n259 0.057900235056877136\n260 0.05499567091464996\n261 0.05225817486643791\n262 0.04965723305940628\n263 0.047162748873233795\n264 0.0448247529566288\n265 0.042583856731653214\n266 0.0404876284301281\n267 0.03846623748540878\n268 0.03656379505991936\n269 0.03474126011133194\n270 0.03301853686571121\n271 0.03138718754053116\n272 0.029825907200574875\n273 0.02834951877593994\n274 0.026956971734762192\n275 0.025631563737988472\n276 0.02436600998044014\n277 0.023172015324234962\n278 0.022032562643289566\n279 0.020945997908711433\n280 0.019925376400351524\n281 0.018947958946228027\n282 0.018015164881944656\n283 0.017131077125668526\n284 0.016299203038215637\n285 0.015500983223319054\n286 0.014750486239790916\n287 0.014032591134309769\n288 0.013345202431082726\n289 0.012698394246399403\n290 0.01207459345459938\n291 0.011492365971207619\n292 0.01093696802854538\n293 0.010417381301522255\n294 0.00991816446185112\n295 0.009446170181035995\n296 0.008989858441054821\n297 0.008559387177228928\n298 0.008147039450705051\n299 0.007757741026580334\n300 0.007389256730675697\n301 0.007044658530503511\n302 0.006710723973810673\n303 0.0064001623541116714\n304 0.006101476028561592\n305 0.005815335549414158\n306 0.005542641505599022\n307 0.005288222339004278\n308 0.00504735391587019\n309 0.00481300288811326\n310 0.004586406983435154\n311 0.004374335985630751\n312 0.00418006582185626\n313 0.00398766715079546\n314 0.003806445049121976\n315 0.0036345398984849453\n316 0.003469737945124507\n317 0.0033193263225257397\n318 0.0031704213470220566\n319 0.0030328468419611454\n320 0.0028969119302928448\n321 0.002769874408841133\n322 0.002651496324688196\n323 0.002537461696192622\n324 0.002429327694699168\n325 0.0023238949943333864\n326 0.002227058634161949\n327 0.0021356826182454824\n328 0.002046206733211875\n329 0.001961295958608389\n330 0.0018779756501317024\n331 0.0018032495863735676\n332 0.0017297988524660468\n333 0.001660587964579463\n334 0.0015922338934615254\n335 0.001529185799881816\n336 0.0014686885988339782\n337 0.0014088788302615285\n338 0.0013549335999414325\n339 0.001300441101193428\n340 0.0012500117300078273\n341 0.0012030750513076782\n342 0.0011578015983104706\n343 0.0011137538822367787\n344 0.0010716395918279886\n345 0.001032186672091484\n346 0.0009945478523150086\n347 0.0009580941405147314\n348 0.0009234772296622396\n349 0.0008895641658455133\n350 0.0008568370249122381\n351 0.0008267969242297113\n352 0.0007982175447978079\n353 0.0007703807204961777\n354 0.0007434813305735588\n355 0.0007172463228926063\n356 0.000692145898938179\n357 0.0006688237190246582\n358 0.0006466774502769113\n359 0.0006259515648707747\n360 0.0006036743870936334\n361 0.0005840150406584144\n362 0.0005650067469105124\n363 0.0005463063716888428\n364 0.0005287617677822709\n365 0.0005127447075210512\n366 0.0004964573308825493\n367 0.0004801164905074984\n368 0.0004650307819247246\n369 0.00045125832548364997\n370 0.00043743467540480196\n371 0.00042381478124298155\n372 0.0004119345103390515\n373 0.00039877710514701903\n374 0.00038778793532401323\n375 0.0003760532708838582\n376 0.00036587988142855465\n377 0.00035486521665006876\n378 0.0003443605965003371\n379 0.0003345482109580189\n380 0.00032480721711181104\n381 0.0003158070903737098\n382 0.00030682998476549983\n383 0.0002986906038131565\n384 0.00029013637686148286\n385 0.0002823488612193614\n386 0.0002745478122960776\n387 0.0002665612264536321\n388 0.0002592500241007656\n389 0.00025265919975936413\n390 0.0002463997807353735\n391 0.00023982446873560548\n392 0.00023375687305815518\n393 0.00022760112187825143\n394 0.0002219078887719661\n395 0.00021633156575262547\n396 0.0002112002403009683\n397 0.00020567633328028023\n398 0.0002004740817938\n399 0.00019598242943175137\n400 0.00019119790522381663\n401 0.00018627531244419515\n402 0.00018186881789006293\n403 0.00017756657325662673\n404 0.00017364235827699304\n405 0.00016970359138213098\n406 0.00016515770403202623\n407 0.00016153061005752534\n408 0.0001580011157784611\n409 0.0001544976985314861\n410 0.00015035203250590712\n411 0.00014694219862576574\n412 0.00014389377611223608\n413 0.00014069581811781973\n414 0.00013784442853648216\n415 0.00013492899597622454\n416 0.0001319578441325575\n417 0.00012948745279572904\n418 0.00012678214989136904\n419 0.00012394963414408267\n420 0.00012093714030925184\n421 0.00011845044355140999\n422 0.00011598298442550004\n423 0.00011360300413798541\n424 0.00011133833322674036\n425 0.000109252127003856\n426 0.00010708072659326717\n427 0.00010466767707839608\n428 0.00010237253445666283\n429 0.00010032426507677883\n430 9.853648953139782e-05\n431 9.619036427466199e-05\n432 9.44423081818968e-05\n433 9.252643212676048e-05\n434 9.069457155419514e-05\n435 8.882630936568603e-05\n436 8.745066588744521e-05\n437 8.563640585634857e-05\n438 8.407929271925241e-05\n439 8.232687832787633e-05\n440 8.112704381346703e-05\n441 7.971753075253218e-05\n442 7.813180855009705e-05\n443 7.67666133469902e-05\n444 7.507671398343518e-05\n445 7.351092790486291e-05\n446 7.202316191978753e-05\n447 7.088021811796352e-05\n448 6.982834020163864e-05\n449 6.873348320368677e-05\n450 6.745582504663616e-05\n451 6.642880180152133e-05\n452 6.520700117107481e-05\n453 6.41400256427005e-05\n454 6.302883411990479e-05\n455 6.20501086814329e-05\n456 6.093967385822907e-05\n457 5.990874706185423e-05\n458 5.91185234952718e-05\n459 5.8222562074661255e-05\n460 5.740937194786966e-05\n461 5.648967999150045e-05\n462 5.545480962609872e-05\n463 5.4496667871717364e-05\n464 5.383801180869341e-05\n465 5.273567512631416e-05\n466 5.226227222010493e-05\n467 5.130334830028005e-05\n468 5.069520921097137e-05\n469 4.9825139285530895e-05\n470 4.904873640043661e-05\n471 4.819737660000101e-05\n472 4.7582710976712406e-05\n473 4.6693232434336096e-05\n474 4.611942858900875e-05\n475 4.555474151857197e-05\n476 4.498410999076441e-05\n477 4.4142219849163666e-05\n478 4.352458199718967e-05\n479 4.3014559196308255e-05\n480 4.223373252898455e-05\n481 4.155796341365203e-05\n482 4.095991971553303e-05\n483 4.068481212016195e-05\n484 4.002403875347227e-05\n485 3.955597640015185e-05\n486 3.890841253451072e-05\n487 3.8348160160239786e-05\n488 3.781267150770873e-05\n489 3.7339483242249116e-05\n490 3.6678160540759563e-05\n491 3.631675281212665e-05\n492 3.581697819754481e-05\n493 3.530664253048599e-05\n494 3.492151154205203e-05\n495 3.4412165405228734e-05\n496 3.394230589037761e-05\n497 3.360862683621235e-05\n498 3.328368620714173e-05\n499 3.27060952258762e-05\n"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 随机创建训练数据\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D_in, H),\n",
    "    nn.ReLU(), # activation function\n",
    "    nn.Linear(H, D_out)\n",
    ")\n",
    "\n",
    "# 拟合效果不好，尝试改变初始权重\n",
    "nn.init.normal_(model[0].weight)\n",
    "nn.init.normal_(model[2].weight)\n",
    "\n",
    "# model  = model.cuda()\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    y_pred = model(x) # model.forward()\n",
    "\n",
    "    # compute loss\n",
    "    loss = loss_fn(y_pred, y) # computation graph\n",
    "    print(it, loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # update weights of w1&w2\n",
    "    with torch.no_grad():# 不让计算图占内存\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n",
    "        \n",
    "        model.zero_grad()"
   ]
  },
  {
   "source": [
    "### 4. optim\n",
    "不用手动更新weight。含不同模型优化方法，如SGD+momentum, RMSProp, Adam..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 720.2042236328125\n1 669.2815551757812\n2 624.4517822265625\n3 584.4412231445312\n4 548.5148315429688\n5 516.002197265625\n6 486.4120178222656\n7 459.094482421875\n8 433.7242431640625\n9 410.1972961425781\n10 388.00762939453125\n11 367.08099365234375\n12 347.23956298828125\n13 328.35699462890625\n14 310.48626708984375\n15 293.5306396484375\n16 277.3670349121094\n17 261.919189453125\n18 247.19970703125\n19 233.1800537109375\n20 219.79916381835938\n21 207.0872802734375\n22 194.89376831054688\n23 183.31271362304688\n24 172.33128356933594\n25 161.923828125\n26 152.0611114501953\n27 142.73854064941406\n28 133.94195556640625\n29 125.63080596923828\n30 117.77931213378906\n31 110.38900756835938\n32 103.43904113769531\n33 96.91029357910156\n34 90.78981018066406\n35 85.03186798095703\n36 79.6490478515625\n37 74.60723876953125\n38 69.8998794555664\n39 65.50548553466797\n40 61.40217590332031\n41 57.57604217529297\n42 53.99755859375\n43 50.65953063964844\n44 47.53276824951172\n45 44.61350631713867\n46 41.89106369018555\n47 39.353248596191406\n48 36.981468200683594\n49 34.76561737060547\n50 32.70003890991211\n51 30.771411895751953\n52 28.960952758789062\n53 27.268836975097656\n54 25.691028594970703\n55 24.212108612060547\n56 22.82971954345703\n57 21.537940979003906\n58 20.322710037231445\n59 19.184566497802734\n60 18.11801528930664\n61 17.119375228881836\n62 16.183990478515625\n63 15.307929992675781\n64 14.48675537109375\n65 13.71688175201416\n66 12.995102882385254\n67 12.31777286529541\n68 11.681915283203125\n69 11.083785057067871\n70 10.520482063293457\n71 9.99105167388916\n72 9.492531776428223\n73 9.020030975341797\n74 8.575222969055176\n75 8.15571403503418\n76 7.760747909545898\n77 7.388157844543457\n78 7.036186695098877\n79 6.703876495361328\n80 6.389740467071533\n81 6.092676162719727\n82 5.811312675476074\n83 5.544090747833252\n84 5.291100025177002\n85 5.051615238189697\n86 4.824484348297119\n87 4.609129905700684\n88 4.40462064743042\n89 4.210761547088623\n90 4.027010917663574\n91 3.8521528244018555\n92 3.6859893798828125\n93 3.5273289680480957\n94 3.376643657684326\n95 3.233017921447754\n96 3.0963895320892334\n97 2.966616153717041\n98 2.8430089950561523\n99 2.7254526615142822\n100 2.6134884357452393\n101 2.5067553520202637\n102 2.404996156692505\n103 2.308000087738037\n104 2.215534210205078\n105 2.127410888671875\n106 2.043379783630371\n107 1.9632456302642822\n108 1.8865852355957031\n109 1.813307523727417\n110 1.7433393001556396\n111 1.6763997077941895\n112 1.6124751567840576\n113 1.551298975944519\n114 1.492783784866333\n115 1.436737060546875\n116 1.383101224899292\n117 1.3317599296569824\n118 1.2826082706451416\n119 1.235525369644165\n120 1.1904560327529907\n121 1.1472768783569336\n122 1.1058363914489746\n123 1.06611168384552\n124 1.0280964374542236\n125 0.9916235208511353\n126 0.9566571712493896\n127 0.9230740666389465\n128 0.890845775604248\n129 0.8599266409873962\n130 0.8302426934242249\n131 0.8017236590385437\n132 0.7743136882781982\n133 0.7479928731918335\n134 0.7227275371551514\n135 0.6984266638755798\n136 0.6750533580780029\n137 0.6525866389274597\n138 0.6309736967086792\n139 0.6102088689804077\n140 0.5902025699615479\n141 0.570952296257019\n142 0.5524332523345947\n143 0.534593403339386\n144 0.5174617767333984\n145 0.5009538531303406\n146 0.48501986265182495\n147 0.46965816617012024\n148 0.4549267292022705\n149 0.44075825810432434\n150 0.42708829045295715\n151 0.4138982892036438\n152 0.4011823236942291\n153 0.38892340660095215\n154 0.3770895004272461\n155 0.365669846534729\n156 0.3546651601791382\n157 0.34403368830680847\n158 0.3337700366973877\n159 0.3238563537597656\n160 0.31428417563438416\n161 0.305042564868927\n162 0.296112060546875\n163 0.28748470544815063\n164 0.2791474759578705\n165 0.27107948064804077\n166 0.2632766366004944\n167 0.2557401657104492\n168 0.2484515905380249\n169 0.24139830470085144\n170 0.23457388579845428\n171 0.2279752790927887\n172 0.22158542275428772\n173 0.21540038287639618\n174 0.2094089835882187\n175 0.20360898971557617\n176 0.1980002522468567\n177 0.19256329536437988\n178 0.18729351460933685\n179 0.18218722939491272\n180 0.17723393440246582\n181 0.17255167663097382\n182 0.16805294156074524\n183 0.16369429230690002\n184 0.15947139263153076\n185 0.1553785800933838\n186 0.15141209959983826\n187 0.1475655436515808\n188 0.14383457601070404\n189 0.14021582901477814\n190 0.13670498132705688\n191 0.13329747319221497\n192 0.12999248504638672\n193 0.12680868804454803\n194 0.12371595203876495\n195 0.12071511149406433\n196 0.11780180037021637\n197 0.11496955156326294\n198 0.11222042143344879\n199 0.10955575853586197\n200 0.10696327686309814\n201 0.1044454574584961\n202 0.10199721157550812\n203 0.09961548447608948\n204 0.09729991108179092\n205 0.09504685550928116\n206 0.09285758435726166\n207 0.0907256156206131\n208 0.08865240216255188\n209 0.08664538711309433\n210 0.08468448370695114\n211 0.0827714204788208\n212 0.08090860396623611\n213 0.07910074293613434\n214 0.07733717560768127\n215 0.07561848312616348\n216 0.07394413650035858\n217 0.07231412827968597\n218 0.07072463631629944\n219 0.06917522102594376\n220 0.06766626983880997\n221 0.06619474291801453\n222 0.06475964188575745\n223 0.0633598193526268\n224 0.061995308846235275\n225 0.06066613271832466\n226 0.05936669558286667\n227 0.05809933692216873\n228 0.05686231330037117\n229 0.055656082928180695\n230 0.054481130093336105\n231 0.053331151604652405\n232 0.052208129316568375\n233 0.05111188814043999\n234 0.050042103976011276\n235 0.04899656027555466\n236 0.047975171357393265\n237 0.04697759076952934\n238 0.046003248542547226\n239 0.04505123943090439\n240 0.04412176460027695\n241 0.0432133786380291\n242 0.042325153946876526\n243 0.04145713895559311\n244 0.04060892015695572\n245 0.03977969288825989\n246 0.038969241082668304\n247 0.038176968693733215\n248 0.03740266337990761\n249 0.03664623945951462\n250 0.0359065942466259\n251 0.03518317639827728\n252 0.03447581082582474\n253 0.03378408029675484\n254 0.03310757875442505\n255 0.0324459969997406\n256 0.0317985936999321\n257 0.031164826825261116\n258 0.030544959008693695\n259 0.029938597232103348\n260 0.029344920068979263\n261 0.028765302151441574\n262 0.028202226385474205\n263 0.027650801464915276\n264 0.02711120992898941\n265 0.026583274826407433\n266 0.02606627345085144\n267 0.02556006982922554\n268 0.025065070018172264\n269 0.02457994408905506\n270 0.024105185642838478\n271 0.023640094324946404\n272 0.023184720426797867\n273 0.022738642990589142\n274 0.022301755845546722\n275 0.02187417633831501\n276 0.021454988047480583\n277 0.021044448018074036\n278 0.02064228057861328\n279 0.02024819329380989\n280 0.01986207440495491\n281 0.019484147429466248\n282 0.01911386102437973\n283 0.01875074952840805\n284 0.018394939601421356\n285 0.018046297132968903\n286 0.017704637721180916\n287 0.017370034009218216\n288 0.01704220101237297\n289 0.01672053150832653\n290 0.016405243426561356\n291 0.016096225008368492\n292 0.015793461352586746\n293 0.01549657341092825\n294 0.015205726027488708\n295 0.014920460060238838\n296 0.014640701934695244\n297 0.014366600662469864\n298 0.014097725041210651\n299 0.01383407972753048\n300 0.013575680553913116\n301 0.013322352431714535\n302 0.013073834590613842\n303 0.012830228544771671\n304 0.012591885402798653\n305 0.012357547879219055\n306 0.012127743102610111\n307 0.011902506463229656\n308 0.0116814486682415\n309 0.011464651674032211\n310 0.011252538301050663\n311 0.011045185849070549\n312 0.010840673930943012\n313 0.010640046559274197\n314 0.010443225502967834\n315 0.010250197723507881\n316 0.010060770437121391\n317 0.009874927811324596\n318 0.009692652150988579\n319 0.009513952769339085\n320 0.00933858286589384\n321 0.009166514500975609\n322 0.008997689932584763\n323 0.008832132443785667\n324 0.008669640868902206\n325 0.008510327897965908\n326 0.008353989571332932\n327 0.008200573734939098\n328 0.008050039410591125\n329 0.007902281358838081\n330 0.007757330778986216\n331 0.007615135982632637\n332 0.007475647609680891\n333 0.00733865424990654\n334 0.007204256020486355\n335 0.007072411477565765\n336 0.006942980922758579\n337 0.006815964821726084\n338 0.006691447924822569\n339 0.006569139659404755\n340 0.006449109874665737\n341 0.006331307347863913\n342 0.006215779110789299\n343 0.006102601997554302\n344 0.005991322919726372\n345 0.00588201591745019\n346 0.005774748045951128\n347 0.005669469013810158\n348 0.005566156469285488\n349 0.005464733578264713\n350 0.005365224555134773\n351 0.0052675511687994\n352 0.005171628203243017\n353 0.005077513866126537\n354 0.004985119681805372\n355 0.004894442390650511\n356 0.004805500619113445\n357 0.004718118347227573\n358 0.004632352385669947\n359 0.004548131953924894\n360 0.004465519450604916\n361 0.004384380299597979\n362 0.004304812755435705\n363 0.0042266384698450565\n364 0.004149938002228737\n365 0.004074587021023035\n366 0.004000633955001831\n367 0.003928054124116898\n368 0.0038568340241909027\n369 0.0037868614308536053\n370 0.0037181833758950233\n371 0.0036507451441138983\n372 0.0035845800302922726\n373 0.0035196365788578987\n374 0.003455853322520852\n375 0.0033932363148778677\n376 0.003331777174025774\n377 0.0032714223489165306\n378 0.0032121941912919283\n379 0.003154060337692499\n380 0.003096938133239746\n381 0.0030408743768930435\n382 0.002985845087096095\n383 0.0029317920561879873\n384 0.002878741128370166\n385 0.0028266722802072763\n386 0.002775539644062519\n387 0.002725321101024747\n388 0.002676004311069846\n389 0.0026276176795363426\n390 0.002580092754215002\n391 0.002533444669097662\n392 0.0024876752868294716\n393 0.0024426630698144436\n394 0.0023985246662050486\n395 0.002355164149776101\n396 0.0023126229643821716\n397 0.0022708417382091284\n398 0.0022297976538538933\n399 0.002189506310969591\n400 0.00214995420537889\n401 0.002111108973622322\n402 0.0020730076357722282\n403 0.0020355889573693275\n404 0.0019988729618489742\n405 0.0019627597648650408\n406 0.0019273210782557726\n407 0.0018925090553238988\n408 0.001858359668403864\n409 0.001824802253395319\n410 0.0017918471712619066\n411 0.0017594934906810522\n412 0.0017277365550398827\n413 0.0016965505201369524\n414 0.0016659402754157782\n415 0.0016358736902475357\n416 0.0016063367947936058\n417 0.0015773458871990442\n418 0.0015488627832382917\n419 0.0015209299745038152\n420 0.0014934907667338848\n421 0.0014665239723399282\n422 0.0014400602085515857\n423 0.001414093072526157\n424 0.001388555159792304\n425 0.0013635181821882725\n426 0.0013389287050813437\n427 0.0013147698482498527\n428 0.001291034510359168\n429 0.0012677344493567944\n430 0.0012448857305571437\n431 0.001222425140440464\n432 0.001200379803776741\n433 0.0011787302792072296\n434 0.0011574600357562304\n435 0.0011365910759195685\n436 0.0011160947615280747\n437 0.0010959715582430363\n438 0.0010762023739516735\n439 0.0010567937279120088\n440 0.0010377236176282167\n441 0.0010190191678702831\n442 0.001000649994239211\n443 0.0009825953748077154\n444 0.0009648768464103341\n445 0.0009474775870330632\n446 0.0009304009145125747\n447 0.0009136275621131063\n448 0.000897150079254061\n449 0.000880962354131043\n450 0.0008650838281027973\n451 0.0008494869689457119\n452 0.0008341649663634598\n453 0.0008191271335817873\n454 0.0008043554844334722\n455 0.0007898469921201468\n456 0.0007756025297567248\n457 0.000761637871619314\n458 0.0007479049381799996\n459 0.0007344186305999756\n460 0.000721164105925709\n461 0.0007081642397679389\n462 0.0006953895790502429\n463 0.0006828653276897967\n464 0.0006705522537231445\n465 0.000658455363009125\n466 0.0006465842016041279\n467 0.000634922063909471\n468 0.0006234716274775565\n469 0.0006122400518506765\n470 0.0006011854275129735\n471 0.0005903460551053286\n472 0.0005797070916742086\n473 0.0005692550330422819\n474 0.000558996747713536\n475 0.0005489159375429153\n476 0.0005390121368691325\n477 0.0005292932037264109\n478 0.0005197518039494753\n479 0.000510387122631073\n480 0.0005011800094507635\n481 0.0004921432700939476\n482 0.00048326552496291697\n483 0.0004745481419377029\n484 0.00046599245979450643\n485 0.0004575925413519144\n486 0.0004493383748922497\n487 0.0004412356356624514\n488 0.00043327847379259765\n489 0.0004254617670085281\n490 0.00041779468301683664\n491 0.0004102593520656228\n492 0.00040286252624355257\n493 0.0003955996944569051\n494 0.00038845426752232015\n495 0.00038146015140227973\n496 0.0003745766880456358\n497 0.0003678215725813061\n498 0.0003611875290516764\n499 0.0003546725201886147\n"
    }
   ],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 随机创建训练数据\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D_in, H),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(H, D_out)\n",
    ")\n",
    "\n",
    "# 拟合效果不好，尝试改变初始权重\n",
    "# nn.init.normal_(model[0].weight)\n",
    "# nn.init.normal_(model[2].weight)\n",
    "\n",
    "# model  = model.cuda()\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-4 # 1e-3 ~ -4对Adam较好\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    y_pred = model(x) # model.forward()\n",
    "\n",
    "    # compute loss\n",
    "    loss = loss_fn(y_pred, y) # computation graph\n",
    "    print(it, loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # update model parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "source": [
    "## 自定义nn Modules\n",
    "继承nn.Module。需要比Sequential更复杂的模型时"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 684.5139770507812\n1 667.6268310546875\n2 651.1676025390625\n3 635.1614379882812\n4 619.5819091796875\n5 604.3728637695312\n6 589.5579833984375\n7 575.171875\n8 561.2047729492188\n9 547.6242065429688\n10 534.4136352539062\n11 521.5889892578125\n12 509.19317626953125\n13 497.1786193847656\n14 485.5188903808594\n15 474.1136474609375\n16 463.02880859375\n17 452.27691650390625\n18 441.8218688964844\n19 431.606689453125\n20 421.6548156738281\n21 411.95623779296875\n22 402.47705078125\n23 393.25445556640625\n24 384.36181640625\n25 375.6669006347656\n26 367.17913818359375\n27 358.9237060546875\n28 350.8595886230469\n29 342.94256591796875\n30 335.21478271484375\n31 327.6778564453125\n32 320.2955322265625\n33 313.05682373046875\n34 305.96783447265625\n35 299.0216979980469\n36 292.2017822265625\n37 285.52008056640625\n38 278.98016357421875\n39 272.5668640136719\n40 266.31854248046875\n41 260.1911926269531\n42 254.17552185058594\n43 248.2553253173828\n44 242.4443359375\n45 236.74142456054688\n46 231.14573669433594\n47 225.6807403564453\n48 220.34019470214844\n49 215.1081085205078\n50 209.9867706298828\n51 204.95079040527344\n52 200.01724243164062\n53 195.17483520507812\n54 190.4239959716797\n55 185.7705841064453\n56 181.21139526367188\n57 176.73666381835938\n58 172.3481903076172\n59 168.04640197753906\n60 163.8311309814453\n61 159.7104949951172\n62 155.6678924560547\n63 151.70999145507812\n64 147.8221435546875\n65 144.03170776367188\n66 140.3226318359375\n67 136.6877899169922\n68 133.12879943847656\n69 129.6429443359375\n70 126.22578430175781\n71 122.87891387939453\n72 119.59480285644531\n73 116.38147735595703\n74 113.23522186279297\n75 110.16072845458984\n76 107.15774536132812\n77 104.21961975097656\n78 101.34231567382812\n79 98.52904510498047\n80 95.7830810546875\n81 93.09233856201172\n82 90.46072387695312\n83 87.89225006103516\n84 85.3847885131836\n85 82.92959594726562\n86 80.5382308959961\n87 78.20191955566406\n88 75.92092895507812\n89 73.69522094726562\n90 71.52325439453125\n91 69.40229797363281\n92 67.32806396484375\n93 65.3091049194336\n94 63.33708190917969\n95 61.415794372558594\n96 59.53913879394531\n97 57.70928955078125\n98 55.92416000366211\n99 54.18116760253906\n100 52.4822998046875\n101 50.82571792602539\n102 49.21208572387695\n103 47.63945770263672\n104 46.1085319519043\n105 44.61790084838867\n106 43.168582916259766\n107 41.76072311401367\n108 40.38926696777344\n109 39.05391311645508\n110 37.75913619995117\n111 36.49986267089844\n112 35.27718734741211\n113 34.08932876586914\n114 32.93657684326172\n115 31.819454193115234\n116 30.73636817932129\n117 29.684165954589844\n118 28.66646957397461\n119 27.678709030151367\n120 26.722288131713867\n121 25.792970657348633\n122 24.89205551147461\n123 24.020662307739258\n124 23.176105499267578\n125 22.35824966430664\n126 21.566749572753906\n127 20.801223754882812\n128 20.06140899658203\n129 19.34572410583496\n130 18.654945373535156\n131 17.98569679260254\n132 17.33903694152832\n133 16.71504020690918\n134 16.11178970336914\n135 15.530134201049805\n136 14.967537879943848\n137 14.424113273620605\n138 13.899791717529297\n139 13.394220352172852\n140 12.9061918258667\n141 12.434524536132812\n142 11.980635643005371\n143 11.543607711791992\n144 11.122608184814453\n145 10.715836524963379\n146 10.324241638183594\n147 9.946754455566406\n148 9.583185195922852\n149 9.23248291015625\n150 8.895296096801758\n151 8.569326400756836\n152 8.256437301635742\n153 7.95406436920166\n154 7.662996768951416\n155 7.382844924926758\n156 7.112895965576172\n157 6.853341579437256\n158 6.6032915115356445\n159 6.362071990966797\n160 6.130342960357666\n161 5.907061576843262\n162 5.692272186279297\n163 5.4850239753723145\n164 5.2856316566467285\n165 5.093820095062256\n166 4.908717155456543\n167 4.730743885040283\n168 4.559595108032227\n169 4.395240783691406\n170 4.237849712371826\n171 4.0863494873046875\n172 3.940643787384033\n173 3.8001906871795654\n174 3.6651298999786377\n175 3.5355522632598877\n176 3.4109573364257812\n177 3.290863037109375\n178 3.175466537475586\n179 3.0641913414001465\n180 2.9569098949432373\n181 2.8538622856140137\n182 2.754613161087036\n183 2.6591875553131104\n184 2.5671770572662354\n185 2.478472948074341\n186 2.393214464187622\n187 2.31093692779541\n188 2.23176908493042\n189 2.1556167602539062\n190 2.0821619033813477\n191 2.0113744735717773\n192 1.9430826902389526\n193 1.8771991729736328\n194 1.813802719116211\n195 1.752581238746643\n196 1.6935356855392456\n197 1.6365758180618286\n198 1.581623911857605\n199 1.5285495519638062\n200 1.4773519039154053\n201 1.427980661392212\n202 1.3803796768188477\n203 1.3343700170516968\n204 1.2900933027267456\n205 1.2471156120300293\n206 1.2057149410247803\n207 1.1657445430755615\n208 1.1271284818649292\n209 1.0898395776748657\n210 1.0538337230682373\n211 1.0190705060958862\n212 0.98539137840271\n213 0.9529050588607788\n214 0.9215000867843628\n215 0.8911693692207336\n216 0.8618680238723755\n217 0.8335183262825012\n218 0.8061329126358032\n219 0.7796119451522827\n220 0.7539860010147095\n221 0.7291979193687439\n222 0.7052180767059326\n223 0.6820434927940369\n224 0.6595981121063232\n225 0.6378821134567261\n226 0.6168839931488037\n227 0.5965659022331238\n228 0.5769026875495911\n229 0.5578632354736328\n230 0.5394365787506104\n231 0.5216078162193298\n232 0.5043392777442932\n233 0.48762479424476624\n234 0.47144341468811035\n235 0.4557778239250183\n236 0.4406169354915619\n237 0.4259679317474365\n238 0.4117925763130188\n239 0.3980637788772583\n240 0.3847714960575104\n241 0.3719078302383423\n242 0.3594464659690857\n243 0.3473794758319855\n244 0.33569175004959106\n245 0.3243722915649414\n246 0.31340864300727844\n247 0.3027969002723694\n248 0.29252317547798157\n249 0.28257983922958374\n250 0.2729470133781433\n251 0.2636176645755768\n252 0.2545873522758484\n253 0.245840385556221\n254 0.23737061023712158\n255 0.2291651964187622\n256 0.22122424840927124\n257 0.2135315090417862\n258 0.20608490705490112\n259 0.19887389242649078\n260 0.19189465045928955\n261 0.185136616230011\n262 0.17859481275081635\n263 0.17226509749889374\n264 0.1661357432603836\n265 0.16020366549491882\n266 0.15446455776691437\n267 0.14891135692596436\n2680.14353778958320618\n269 0.13834285736083984\n270 0.13331806659698486\n271 0.12845733761787415\n272 0.12375663965940475\n273 0.11921028792858124\n274 0.11481417715549469\n275 0.11056502163410187\n276 0.10645502805709839\n277 0.10248388350009918\n278 0.09864620119333267\n279 0.09493784606456757\n280 0.09136299788951874\n281 0.087892085313797\n282 0.08454932272434235\n283 0.08131973445415497\n284 0.07820191979408264\n285 0.0751914232969284\n286 0.07228522002696991\n287 0.06947942823171616\n288 0.06677629798650742\n289 0.06416963040828705\n290 0.06165509298443794\n291 0.05922938883304596\n292 0.0568898469209671\n293 0.054636042565107346\n294 0.052459076046943665\n295 0.050362035632133484\n296 0.04834137484431267\n297 0.046394165605306625\n298 0.04451791197061539\n299 0.04271014407277107\n300 0.04097052291035652\n301 0.03929270803928375\n302 0.0376785472035408\n303 0.036124587059020996\n304 0.03462895005941391\n305 0.033189818263053894\n306 0.03180446848273277\n307 0.030472073704004288\n308 0.029190631583333015\n309 0.027958478778600693\n310 0.02677357941865921\n311 0.025634456425905228\n312 0.024539964273571968\n313 0.02348799630999565\n314 0.022476935759186745\n315 0.02150595560669899\n316 0.02057340182363987\n317 0.019677847623825073\n318 0.018817923963069916\n319 0.017992550507187843\n320 0.01720074936747551\n321 0.016440536826848984\n322 0.015711193904280663\n323 0.015011882409453392\n324 0.014341222122311592\n325 0.013698049820959568\n326 0.013081399723887444\n327 0.012490561231970787\n328 0.011924146674573421\n329 0.011381542310118675\n330 0.010861832648515701\n331 0.0103639867156744\n332 0.009887222200632095\n333 0.009430869482457638\n334 0.008994054049253464\n335 0.00857587717473507\n336 0.00817579310387373\n337 0.007793099153786898\n338 0.007427060045301914\n339 0.0070769526064395905\n340 0.006742204073816538\n341 0.006422196514904499\n342 0.006116376258432865\n343 0.005824112333357334\n344 0.005544867366552353\n345 0.00527806906029582\n346 0.005023357458412647\n347 0.004780062474310398\n348 0.004547812044620514\n349 0.004326083697378635\n350 0.004114494659006596\n351 0.003912650048732758\n352 0.003720033448189497\n353 0.0035363268107175827\n354 0.003361146431416273\n355 0.003194099524989724\n356 0.0030348089057952166\n357 0.0028830133378505707\n358 0.002738369395956397\n359 0.002600514329969883\n360 0.002469212282449007\n361 0.0023441482335329056\n362 0.0022250779438763857\n363 0.0021117106080055237\n364 0.002003786154091358\n365 0.0019010265823453665\n366 0.0018033083761110902\n367 0.0017102810088545084\n368 0.0016218165401369333\n369 0.0015376637456938624\n370 0.00145764893386513\n371 0.0013815707061439753\n372 0.0013092539738863707\n373 0.0012405135203152895\n374 0.001175198471173644\n375 0.0011131474748253822\n376 0.001054188935086131\n377 0.000998196890577674\n378 0.0009450353682041168\n379 0.0008945654844865203\n380 0.000846638809889555\n381 0.0008011583122424781\n382 0.0007580179953947663\n383 0.0007170866592787206\n384 0.0006782328709959984\n385 0.0006413927767425776\n386 0.0006064664339646697\n387 0.000573331315536052\n388 0.0005419448134489357\n389 0.0005121958674862981\n390 0.0004839895118493587\n391 0.00045726282405667007\n392 0.00043195701437070966\n393 0.0004079825012013316\n394 0.00038528413278982043\n395 0.00036378088407218456\n396 0.0003434313111938536\n397 0.00032416527392342687\n398 0.00030594010604545474\n399 0.00028869271045550704\n400 0.00027237029280513525\n401 0.0002569384523667395\n402 0.00024233873409684747\n403 0.00022852921392768621\n404 0.00021547502547036856\n405 0.00020314534776844084\n406 0.00019147692364640534\n407 0.0001804538769647479\n408 0.00017004081746563315\n409 0.00016020596376620233\n410 0.00015091303794179112\n411 0.00014214201655704528\n412 0.0001338539004791528\n413 0.00012603032519109547\n414 0.00011865353735629469\n415 0.00011168035416631028\n416 0.00010510323045309633\n417 9.890184446703643e-05\n418 9.305067214882001e-05\n419 8.753086149226874e-05\n420 8.232513209804893e-05\n421 7.742068555671722e-05\n422 7.279669080162421e-05\n423 6.843925802968442e-05\n424 6.433012458728626e-05\n425 6.046076669008471e-05\n426 5.6813452829374e-05\n427 5.337905531632714e-05\n428 5.014771886635572e-05\n429 4.709973291028291e-05\n430 4.423137579578906e-05\n431 4.153138797846623e-05\n432 3.899129660567269e-05\n433 3.660221045720391e-05\n434 3.435344115132466e-05\n435 3.2239498978015035e-05\n436 3.0247831091401167e-05\n437 2.8377133276080713e-05\n438 2.6617630282999016e-05\n439 2.4960998416645452e-05\n440 2.3408185370499268e-05\n441 2.1946249034954235e-05\n442 2.0571682398440316e-05\n443 1.9282137145637535e-05\n444 1.8071248632622883e-05\n445 1.6932892322074622e-05\n446 1.586470170877874e-05\n447 1.4859815564705059e-05\n448 1.391807927575428e-05\n449 1.3033257346251048e-05\n450 1.2202888683532365e-05\n451 1.1424238437029999e-05\n452 1.0693733202060685e-05\n453 1.0009264769905712e-05\n454 9.365267942484934e-06\n455 8.762684046814684e-06\n456 8.196871931431815e-06\n457 7.666096280445345e-06\n458 7.169607670221012e-06\n459 6.704583938699216e-06\n460 6.267914613999892e-06\n461 5.859016710019205e-06\n462 5.475451871461701e-06\n463 5.117131877341308e-06\n464 4.780900781042874e-06\n465 4.466702193894889e-06\n466 4.172455192019697e-06\n467 3.89712431569933e-06\n468 3.6396431823959574e-06\n469 3.3978017199842725e-06\n470 3.171888920405763e-06\n471 2.9609091143356636e-06\n472 2.7637454422801966e-06\n473 2.579249212431023e-06\n474 2.4062296688498463e-06\n475 2.2451149561675265e-06\n476 2.0941620277881157e-06\n477 1.9525455172697548e-06\n478 1.82087387656793e-06\n479 1.6981257431325503e-06\n480 1.5825713717276813e-06\n481 1.475208023293817e-06\n482 1.3754181509284535e-06\n483 1.2813455896321102e-06\n484 1.1941477850996307e-06\n485 1.112357040256029e-06\n486 1.0363602314100717e-06\n487 9.652969765738817e-07\n488 8.988728836811788e-07\n489 8.368669455194322e-07\n490 7.791741154505871e-07\n491 7.250598628161242e-07\n492 6.749453973498021e-07\n493 6.281973696786736e-07\n494 5.84535087000404e-07\n495 5.439258075057296e-07\n496 5.059112027083756e-07\n497 4.707629841504968e-07\n498 4.377336608740734e-07\n499 4.0698537873140594e-07\n"
    }
   ],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 随机创建训练数据\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        # define model architecture\n",
    "        self.linear1 = nn.Linear(D_in, H, bias=False)\n",
    "        self.linear2 = nn.Linear(H, D_out, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear2(self.linear1(x).clamp(min=0))\n",
    "        return y_pred\n",
    "\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-4 # 1e-3 ~ -4对Adam较好\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for it in range(500):\n",
    "    # Forward pass\n",
    "    y_pred = model(x) # model.forward()\n",
    "\n",
    "    # compute loss\n",
    "    loss = loss_fn(y_pred, y) # computation graph\n",
    "    print(it, loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # update model parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "source": [
    "# 数据集"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.dataset"
   ]
  }
 ]
}